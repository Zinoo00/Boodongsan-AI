"""
ì±„íŒ… UI ì»´í¬ë„ŒíŠ¸
"""

import streamlit as st
import logging
from ..models import RealEstateAssistant
from ..config import BEDROCK_MODEL_ID, BEDROCK_INFERENCE_PROFILE_ID
from ..utils.aws_knowledge_base import format_retrieval_results

logger = logging.getLogger(__name__)


def render_chat_interface(aws_region: str, knowledge_base_id: str, max_results: int, search_type: str = "hybrid", model_or_profile_id: str | None = None):
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
    st.header("ğŸ’¬ ë¶€ë™ì‚° AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ëŒ€í™”í•˜ê¸°")
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ 
    if prompt := st.chat_input("ë¶€ë™ì‚°ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!", key="chat_input"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # Knowledge Base ê²€ìƒ‰
                assistant = RealEstateAssistant(aws_region)
                
                if knowledge_base_id:
                    logger.info(f"AI ì±„íŒ… ì‹œì‘ - Knowledge Base ID: {knowledge_base_id}, ê²€ìƒ‰ íƒ€ì…: {search_type}")
                    knowledge_response = assistant.query_knowledge_base(prompt, knowledge_base_id, max_results, search_type)
                    
                    # ì—ëŸ¬ ì²´í¬
                    if 'error' in knowledge_response:
                        logger.error(f"Knowledge Base ê²€ìƒ‰ ì˜¤ë¥˜: {knowledge_response['error']}")
                        response = f"âŒ Knowledge Base ê²€ìƒ‰ ì˜¤ë¥˜: {knowledge_response['error']}"
                    else:
                        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                        context = format_retrieval_results(knowledge_response)
                        logger.info(f"ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)}ì")
                        
                        # AI ì‘ë‹µ ìƒì„±
                        logger.info("Claude ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„± ì¤‘...")
                        # ì‚¬ì´ë“œë°” ì„ íƒ > í™˜ê²½ë³€ìˆ˜ ìš°ì„ ìˆœìœ„ ì ìš©
                        chosen_model = model_or_profile_id or BEDROCK_INFERENCE_PROFILE_ID or BEDROCK_MODEL_ID
                        response = assistant.generate_response(prompt, context, chosen_model)
                        
                        # ì‘ë‹µì´ ì—ëŸ¬ ë©”ì‹œì§€ì¸ì§€ í™•ì¸
                        if response.startswith("AWS Bedrockì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤") or \
                           response.startswith("ëª¨ë¸ IDê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤") or \
                           response.startswith("Bedrock ì‘ë‹µ ìƒì„± ì˜¤ë¥˜") or \
                           response.startswith("âŒ BEDROCK_MODEL_ID"):
                            logger.error(f"Claude ëª¨ë¸ ì˜¤ë¥˜: {response}")
                            # ì—ëŸ¬ ë©”ì‹œì§€ì— ì—ëŸ¬ ì½”ë“œ ì •ë³´ ì¶”ê°€
                            if "ValidationException" in response:
                                response = f"âŒ **ValidationException**: {response}"
                            elif "AccessDeniedException" in response:
                                response = f"âŒ **AccessDeniedException**: {response}"
                            elif "ResourceNotFoundException" in response:
                                response = f"âŒ **ResourceNotFoundException**: {response}"
                            elif "ThrottlingException" in response:
                                response = f"âŒ **ThrottlingException**: {response}"
                            else:
                                response = f"âŒ {response}"
                        else:
                            logger.info(f"AI ì‘ë‹µ ìƒì„± ì™„ë£Œ - ìµœì¢… ì‘ë‹µ ê¸¸ì´: {len(response)}ì")
                else:
                    logger.warning("Knowledge Base IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    # Knowledge Baseê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
                    response = "âš ï¸ Knowledge Base IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ Knowledge Base IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
                
                st.markdown(response)
                
                # AI ë©”ì‹œì§€ ì¶”ê°€
                st.session_state.messages.append({"role": "assistant", "content": response})
