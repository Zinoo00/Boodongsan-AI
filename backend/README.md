# ğŸ  Boodongsan Backend

Korean Real Estate RAG AI Chatbot - Backend API Server

## ğŸš€ **Quick Start (2ë¶„ ì‹¤í–‰)**

### **Method 1: Docker (ê¶Œì¥)**
```bash
# 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì— í•„ìˆ˜ API í‚¤ë“¤ ì…ë ¥

# 2. Dockerë¡œ ì‹¤í–‰
docker-compose up -d

# 3. ì ‘ì† í™•ì¸  
curl http://localhost:8000/api/v1/health
```

### **Method 2: ë¡œì»¬ ê°œë°œ**
```bash
# 1. uv ì„¤ì¹˜ (if not installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. í™˜ê²½ë³€ìˆ˜ ë° ì˜ì¡´ì„± ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì— í•„ìˆ˜ API í‚¤ë“¤ ì…ë ¥
uv sync

# 3. ì™¸ë¶€ ì„œë¹„ìŠ¤ë§Œ Dockerë¡œ ì‹œì‘
docker-compose up -d redis neo4j

# 4. ì„œë²„ ì‹œì‘
uv run uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ”§ **í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •**

`.env` íŒŒì¼ì—ì„œ ë‹¤ìŒ í•­ëª©ë“¤ì„ ì„¤ì •í•˜ì„¸ìš”:

### **Required (í•„ìˆ˜)**
```bash
# AWS Bedrock
AWS_ACCESS_KEY_ID=your_aws_access_key  
AWS_SECRET_ACCESS_KEY=your_aws_secret_key

# Supabase  
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Cloudflare Workers AI
CLOUDFLARE_ACCOUNT_ID=your_account_id
CLOUDFLARE_API_TOKEN=your_api_token

# êµ­í† êµí†µë¶€ API
MOLIT_API_KEY=your_molit_api_key
```

### **Optional (ì„ íƒì‚¬í•­)**  
```bash
# Redis (ê¸°ë³¸ê°’: redis://localhost:6379/0)
REDIS_URL=redis://localhost:6379/0

# AWS OpenSearch
OPENSEARCH_HOST=search-your-domain.ap-northeast-2.es.amazonaws.com
OPENSEARCH_PORT=443
OPENSEARCH_INDEX_NAME=boda_vectors
OPENSEARCH_AUTH_MODE=sigv4

# Seoul Open Data (ì‹¤ì‹œê°„ ë„ì‹œë°ì´í„°)
# SEOUL_OPEN_API_KEY=sample

# LightRAG / Neo4j
USE_LIGHTRAG=true
LIGHTRAG_WORKING_DIR=./lightrag_storage
LIGHTRAG_WORKSPACE=boda
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=neo4j
```

## ğŸ†˜ **ë¬¸ì œ í•´ê²°**

### **ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ**

#### **1. ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì§€ ì•Šì„ ë•Œ**
```bash
# ëª¨ë“  ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose down && docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f backend

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¬ì‹œì‘
docker-compose restart redis
```

#### **2. í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜**
```bash
# .env íŒŒì¼ í™•ì¸
cat .env | grep -v "#" | grep -v "^$"

# í•„ìˆ˜ ë³€ìˆ˜ê°€ ëª¨ë‘ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
python -c "from core.config import settings; print('âœ… ì„¤ì • ì™„ë£Œ')"
```

#### **3. í¬íŠ¸ ì¶©ëŒ**
```bash
# í¬íŠ¸ ì‚¬ìš© í™•ì¸
lsof -i :8000
netstat -an | grep :8000

# í¬íŠ¸ ë³€ê²½ (docker-compose.ymlì—ì„œ)
# ports: - "8001:8000"
```

#### **4. API í‚¤ ì˜¤ë¥˜**
```bash
# AWS ìê²©ì¦ëª… í…ŒìŠ¤íŠ¸
aws sts get-caller-identity

# Supabase ì—°ê²° í…ŒìŠ¤íŠ¸  
curl -H "apikey: YOUR_ANON_KEY" "https://your-project.supabase.co/rest/v1/"
```

---

## ğŸ› ï¸ **ê°œë°œ ë„êµ¬**

### **ì½”ë“œ í’ˆì§ˆ ë„êµ¬**
```bash
# ë¦°íŠ¸ ë° í¬ë§·íŒ…
uv run ruff check .
uv run ruff format .

# íƒ€ì… ì²´í¬
uv run mypy .

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest
```

### **ì˜ì¡´ì„± ê´€ë¦¬ (uv)**
```bash
# íŒ¨í‚¤ì§€ ì¶”ê°€
uv add fastapi

# ê°œë°œ ë„êµ¬ ì¶”ê°€
uv add --group dev pytest

# ì˜ì¡´ì„± ì—…ë°ì´íŠ¸
uv sync --upgrade
```

---

## ğŸŒ **API Endpoints**

### **Main Endpoints**
- **`GET /`** - API ì •ë³´
- **`GET /api/v1/health`** - í—¬ìŠ¤ì²´í¬
- **`GET /api/v1/info`** - ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´

### **Chat & AI**
- **`POST /api/v1/chat/send`** - ì±—ë´‡ ëŒ€í™”
- **`GET /api/v1/chat/history/{conversation_id}?user_id=`** - ëŒ€í™” ê¸°ë¡ ì¡°íšŒ

### **Properties & Policies**  
- **`POST /api/v1/properties/search`** - ë¶€ë™ì‚° ê²€ìƒ‰
- **`GET /api/v1/properties/{property_id}`** - ë§¤ë¬¼ ìƒì„¸
- **`POST /api/v1/policies/match`** - ì •ì±… ë§¤ì¹­
- **`POST /api/v1/policies/search`** - ì •ì±… ê²€ìƒ‰
- **`GET /api/v1/policies/`** - ì •ì±… ëª©ë¡

### **Users**
- **`GET /api/v1/users/{user_id}/profile`** - ì‚¬ìš©ì í”„ë¡œí•„
- **`GET /api/v1/users/{user_id}/conversations/{conversation_id}`** - ì‚¬ìš©ì ëŒ€í™” ì´ë ¥

### **Users**
- **`GET /api/v1/users/{user_id}`** - ì‚¬ìš©ì ì •ë³´
- **`POST /api/v1/users/profile`** - í”„ë¡œí•„ ìƒì„±/ìˆ˜ì •

### **Documentation**
- **`GET /docs`** - Swagger UI (ê°œë°œëª¨ë“œ)  
- **`GET /redoc`** - ReDoc UI (ê°œë°œëª¨ë“œ)

---

## ğŸ—ï¸ **Architecture**

```
backend/
â”œâ”€â”€ ğŸ“ ai/               # AI services (AWS Bedrock client)
â”œâ”€â”€ ğŸ“ api/              # FastAPI application & routers  
â”œâ”€â”€ ğŸ“ core/             # Configuration & Supabase/Redis helpers
â”œâ”€â”€ ğŸ“ services/         # Business logic (RAG, LightRAG, DataService ë“±)
â”œâ”€â”€ ğŸ“ data/             # ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ ğŸ“ docs/             # ë°±ì—”ë“œ ë¬¸ì„œ
â”œâ”€â”€ ğŸ“ migrations/       # Supabase / LightRAG SQL ìŠ¤í‚¤ë§ˆ
â””â”€â”€ ğŸ“„ docker-compose.yml # Multi-service orchestration
```

**Key Services**: FastAPI â†’ Supabase (DB) â†’ Redis (Cache) â†’ AWS OpenSearch (Vectors) â†’ AWS Bedrock (AI) â†’ Seoul City Data (Real-time context)

## ğŸ”§ Configuration

### Environment Variables
Copy `.env.example` to `.env` and configure:

```bash
# Database - Supabase (required)
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_key
SUPABASE_DB_PASSWORD=your_supabase_db_password  # from Supabase Project Settings â†’ Database

# Redis Cache
REDIS_URL=redis://localhost:6379/0

# LightRAG / Neo4j
USE_LIGHTRAG=true
LIGHTRAG_WORKING_DIR=./lightrag_storage
LIGHTRAG_WORKSPACE=boda
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=neo4j

# AWS OpenSearch Vector DB
OPENSEARCH_HOST=search-your-domain.ap-northeast-2.es.amazonaws.com
OPENSEARCH_PORT=443
OPENSEARCH_INDEX_NAME=boda_vectors
OPENSEARCH_AUTH_MODE=sigv4

# AI Services
AWS_ACCESS_KEY_ID=your_aws_key
AWS_SECRET_ACCESS_KEY=your_aws_secret
CLOUDFLARE_ACCOUNT_ID=your_cf_account
CLOUDFLARE_API_TOKEN=your_cf_token

# Korean Real Estate APIs
MOLIT_API_KEY=your_molit_key
```

## ğŸ—„ï¸ Database Setup

### Supabase Integration

The application now uses the Supabase Python client library for enhanced database connectivity:

- **Primary Database**: Supabase PostgreSQL via Python client
- **Connection Management**: Automatic retry logic and health monitoring
- **Authentication**: Service role key for server-side operations
- **Real-time capabilities**: Ready for Supabase real-time subscriptions

### uv Configuration Features

The `pyproject.toml` includes comprehensive tool configuration:

- **Ruff**: Fast linting and formatting with Python 3.11+ rules
- **MyPy**: Strict type checking configuration  
- **Pytest**: Async testing setup with coverage
- **Dependency Groups**: Modular installation options

## ğŸ¯ uv Advantages for This Project

1. **âš¡ Speed**: 10-100x faster than pip for installation and resolution
2. **ğŸ”’ Security**: Built-in lock file ensures reproducible builds  
3. **ğŸ“¦ Modularity**: Dependency groups for feature-based installation
4. **ğŸ Python Management**: Built-in Python version management
5. **ğŸ”„ Compatibility**: Drop-in replacement for pip/poetry/pipenv
6. **ğŸ› ï¸ Tooling**: Integrated project management commands

## ğŸ“Š Performance Optimization

### uv Performance Tips
```bash
# Pre-compiled wheels cache
uv cache clean       # Clear cache if needed
uv cache dir         # Check cache location

# Parallel installations
uv sync --no-cache   # Skip cache for fresh install

# Minimal installs for production
uv sync --no-dev     # Skip development dependencies
```

### Production Deployment
```bash
# Multi-stage Docker builds with uv
FROM python:3.11-slim as builder
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-cache

# Runtime stage
FROM python:3.11-slim
COPY --from=builder /app/.venv /app/.venv
ENV PATH="/app/.venv/bin:$PATH"
```

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# With coverage reporting
uv run pytest --cov=backend --cov-report=html

# Run specific test files
uv run pytest tests/test_api.py

# Async test debugging
uv run pytest -v --log-level=DEBUG
```

## ğŸ“ˆ Monitoring

The application includes:
- **Health checks**: `/api/v1/health` with Supabase and Redis status
- **Metrics**: Prometheus metrics on port 9090 (if enabled)
- **Logging**: Structured logging with configurable levels
- **Database monitoring**: Supabase connection health and cache statistics

### Health Check Response
```json
{
  "supabase": {
    "status": true,
    "latency_ms": 45.2
  },
  "redis": {
    "status": true,
    "latency_ms": 12.3,
    "memory_usage": {
      "used_memory": "2.5MB",
      "used_memory_peak": "5.1MB"
    }
  },
  "cache_stats": {
    "hits": 1250,
    "misses": 89,
    "hit_rate_percent": 93.35
  }
}
```

## ğŸ“‹ Recent Changes

### v1.1.0 - Supabase Integration (Latest)
- **âœ… Migration to Supabase Client**: Replaced SQLAlchemy/asyncpg with Supabase Python client
- **âœ… Enhanced Connection Management**: Improved error handling and retry logic
- **âœ… Service Layer Updates**: All services now use Supabase client operations
- **âœ… LangChain Compatibility**: Fixed deprecated import warnings
- **âœ… Performance Improvements**: Streamlined database operations and connection pooling

## ğŸ¤ Contributing

1. Install development environment: `uv sync --group dev`
2. Set up pre-commit: `uv run pre-commit install` (if using)
3. Run tests: `uv run pytest`
4. Check code quality: `uv run ruff check .`
5. Format code: `uv run ruff format .`

## ğŸ“ Migration from pip/poetry

If migrating from existing tools:

```bash
# From requirements.txt
uv add $(cat requirements.txt)

# From poetry
# Export pyproject.toml deps, then import to uv

# From pipenv  
# Export Pipfile deps, then import to uv
```

## ğŸ”— Useful Links

- [uv Documentation](https://docs.astral.sh/uv/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Pydantic V2 Migration](https://docs.pydantic.dev/2.0/migration/)
- [Ruff Configuration](https://docs.astral.sh/ruff/configuration/)

---

**Korean Real Estate RAG AI Backend** - Powered by uv for optimal Python package management
