# ğŸ  BODA - Korean Real Estate RAG AI Chatbot

ë¶€ë™ì‚° ë§¤ë¬¼ ì¶”ì²œ ë° ì •ë¶€ ì§€ì› ì •ì±… ë§¤ì¹­ AI ì±—ë´‡

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116-green.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.38-red.svg)](https://streamlit.io/)

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- ğŸ¤– **AI ê¸°ë°˜ ëŒ€í™”í˜• ë¶€ë™ì‚° ìƒë‹´**
- ğŸ˜ï¸ **ë§ì¶¤í˜• ë§¤ë¬¼ ì¶”ì²œ** (ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰)
- ğŸ“‹ **ì •ë¶€ ì§€ì› ì •ì±… ë§¤ì¹­** (ìê²© ì¡°ê±´ ìë™ ë¶„ì„)
- ğŸ” **ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´** (êµ­í† êµí†µë¶€ OpenAPI)
- ğŸ’¬ **ëŒ€í™” ì´ë ¥ ê´€ë¦¬** (ê²½ëŸ‰ JSON ìŠ¤í† ë¦¬ì§€)

## ğŸ—ï¸ ê¸°ìˆ  ìŠ¤íƒ

### Backend
- **Framework**: FastAPI, Uvicorn
- **AI**: AWS Bedrock (Claude + Titan Embeddings)
- **RAG**: LightRAG (Knowledge Graph RAG with default settings)
  - **Vector DB**: NanoVectorDB (embedded, no external service needed)
  - **Graph Storage**: NetworkX (local graph storage)
  - **Document Status**: JSON (local storage)
- **Cache**: Redis
- **OpenAPI**: êµ­í† êµí†µë¶€ (MOLIT), Seoul Open Data

### Frontend
- **Framework**: Streamlit (minimal chatbot interface)
- **UI**: Native Streamlit components (st.chat_message, st.chat_input)

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- Python 3.11
- uv (íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €)
- Docker & Docker Compose
- AWS ê³„ì • (Bedrock)

### ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/yourusername/boodongsan.git
cd boodongsan

# 2. ë°±ì—”ë“œ ì„¤ì •
cd backend
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘ (API í‚¤ ì…ë ¥ í•„ìš”)

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
uv sync

# 4. ì™¸ë¶€ ì„œë¹„ìŠ¤ ì‹œì‘ (Redis only - LightRAG uses embedded storage)
docker-compose up -d redis

# 5. ë°±ì—”ë“œ ì‹¤í–‰
uv run uvicorn api.main:app --reload

# 6. í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„)
cd ../frontend
pip install -r requirements.txt
streamlit run app.py
```

### ì ‘ì†

- í”„ë¡ íŠ¸ì—”ë“œ: http://localhost:8501
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
boodongsan/
â”œâ”€â”€ backend/              # FastAPI ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ api/             # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ core/            # í•µì‹¬ ì„¤ì • (config, database)
â”‚   â”œâ”€â”€ services/        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â””â”€â”€ tests/           # í…ŒìŠ¤íŠ¸
â”œâ”€â”€ frontend/            # Streamlit í”„ë¡ íŠ¸ì—”ë“œ
â”‚   â”œâ”€â”€ components/      # UI ì»´í¬ë„ŒíŠ¸
â”‚   â””â”€â”€ app.py          # ë©”ì¸ ì•±
â””â”€â”€ docker-compose.yml   # Docker ì„¤ì •
```

## ğŸ”§ ê°œë°œ

### ì½”ë“œ í’ˆì§ˆ

```bash
# Lint ê²€ì‚¬
uv run ruff check .

# ì½”ë“œ í¬ë§·íŒ…
uv run ruff format .

# íƒ€ì… ê²€ì‚¬
uv run mypy .
```

### í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
uv run pytest

# ì»¤ë²„ë¦¬ì§€ í¬í•¨
uv run pytest --cov
```

## ğŸŒ í™˜ê²½ ë³€ìˆ˜

í•µì‹¬ í™˜ê²½ ë³€ìˆ˜ (.env íŒŒì¼):

```bash
# LightRAG (uses default NanoVectorDB, NetworkX, JSON)
LIGHTRAG_WORKING_DIR=./lightrag_storage
LIGHTRAG_WORKSPACE=BODA

# AWS Bedrock (AI)
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
AWS_REGION=ap-northeast-2

# OpenAPI
MOLIT_API_KEY=your_molit_key

# Note: No OpenSearch configuration needed - LightRAG uses embedded storage!
```

ì „ì²´ ì„¤ì •ì€ `backend/.env.example` ì°¸ê³ 

## ğŸ“Š ì•„í‚¤í…ì²˜

```
User Query
    â†“
Streamlit Frontend (8501)
    â†“
FastAPI Backend (8000)
    â†“
LightRAG Service (Unified RAG)
    â”œâ”€â†’ Knowledge Graph (NetworkX)
    â”œâ”€â†’ Vector Search (NanoVectorDB)
    â””â”€â†’ AWS Bedrock (Embeddings + LLM)
            â†“
        Response to User
```

### Data Flow

1. User sends message via Streamlit
2. Backend queries LightRAG with hybrid mode
3. LightRAG performs:
   - **Knowledge Graph Reasoning**: NetworkX graph traversal
   - **Vector Similarity Search**: NanoVectorDB (embedded)
   - **Entity Extraction**: AWS Bedrock Claude
   - **Embeddings**: AWS Bedrock Titan
4. LightRAG generates context-aware response
5. Response displayed in Streamlit chat

### LightRAG Default Settings

- **Vector DB**: NanoVectorDB (embedded, no external service)
- **Graph Storage**: NetworkX (local graph storage)
- **Document Status**: JSON files (local storage)
- **Chunk Size**: 1200 tokens (default)
- **Embedding Batch**: 32 (default)
- **Query Modes**: hybrid, local, global, naive

### Migration from OpenSearch

This project has been migrated from OpenSearch to LightRAG:
- **Before**: External OpenSearch vector DB + LightRAG knowledge graph
- **Now**: LightRAG with embedded NanoVectorDB (all-in-one)
- **Benefits**:
  - No external vector DB service required
  - Simplified setup and deployment
  - Integrated knowledge graph + vector search
  - Optimized performance with default settings

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License
